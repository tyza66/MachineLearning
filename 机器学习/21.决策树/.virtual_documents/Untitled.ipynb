import pandas as pd


titanic = pd.read_csv("./titanic.csv")


titanic.head()


# 筛选特征值和目标值
x = titanic[["pclass","age","sex"]]
y = titanic["survived"]


x.head()


y.head()


# 缺失值处理
x["age"].fillna(x["age"].mean(),inplace=True)


x.head()


# 转换成字典
x = x.to_dict(orient="records")


from sklearn.model_selection import train_test_split
# 数据集划分
x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=22)


# 字典特征抽取
from sklearn.feature_extraction import DictVectorizer
transfer = DictVectorizer()
x_train = transfer.fit_transform(x_train)
x_test =  transfer.fit_transform(x_test)


from sklearn.tree import DecisionTreeClassifier,export_graphviz


estimator = DecisionTreeClassifier(criterion="entropy",max_depth=8) # 默认是gini基尼系数 我们用信息熵 信息增益
estimator.fit(x_train, y_train) # 训练

# 4 模型评估
# 方法1：直接比对真实值和预测值
y_predict = estimator.predict(x_test)
print("预测值为：", y_predict)
print("比对真实值和预测值：", y_test == y_predict) # 比对真实值和预测值

# 方法2：计算准确率
score = estimator.score(x_test, y_test)
print("准确率为：", score)

# 可视化决策树
export_graphviz(estimator, out_file="titanic_tree.dot", feature_names=transfer.get_feature_names_out())
