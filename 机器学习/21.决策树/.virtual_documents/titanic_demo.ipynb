import pandas as pd


titanic = pd.read_csv("./titanic.csv")


titanic.head()


# 筛选特征值和目标值
x = titanic[["pclass","age","sex"]]
y = titanic["survived"]


x.head()


y.head()


# 缺失值处理
x["age"].fillna(x["age"].mean(),inplace=True)


x.head()


# 转换成字典
x = x.to_dict(orient="records")


from sklearn.model_selection import train_test_split
# 数据集划分
x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=22)


# 字典特征抽取
from sklearn.feature_extraction import DictVectorizer
transfer = DictVectorizer()
x_train = transfer.fit_transform(x_train)
x_test =  transfer.fit_transform(x_test)


from sklearn.tree import DecisionTreeClassifier,export_graphviz


estimator = DecisionTreeClassifier(criterion="entropy",max_depth=8) # 默认是gini基尼系数 我们用信息熵 信息增益
estimator.fit(x_train, y_train) # 训练

# 4 模型评估
# 方法1：直接比对真实值和预测值
y_predict = estimator.predict(x_test)
print("预测值为：", y_predict)
print("比对真实值和预测值：", y_test == y_predict) # 比对真实值和预测值

# 方法2：计算准确率
score = estimator.score(x_test, y_test)
print("准确率为：", score)

# 可视化决策树
export_graphviz(estimator, out_file="titanic_tree.dot", feature_names=transfer.get_feature_names_out())





from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV


# 可以通过网格搜索自动调参
estimator = RandomForestClassifier()
# 加入网格搜索和交叉验证
param_dict = {"n_estimators":[120,200,300,500,800,1200],
             "max_depth":[5,8,15,25,30]}
estimator = GridSearchCV(estimator, param_grid=param_dict, cv=3)

estimator.fit(x_train, y_train)

y_predict = estimator.predict(x_test) 
print("预测值为：", y_predict)
print("比对真实值和预测值：", y_test == y_predict) 

score = estimator.score(x_test, y_test)
print("准确率为：", score)

# 最佳参数
print("最佳参数：", estimator.best_params_)
# 最佳结果
print("最佳结果：", estimator.best_score_)
# 最佳估计器
print("最佳估计器：", estimator.best_estimator_)
# 交叉验证结果
print("交叉验证结果：", estimator.cv_results_)
