K-Nearest Neighbors

核心思想就是根据我最近的邻居区分我的类别

定义:如果一个样本在特征控件中的k个最相似(既特征中最临近)的样本中的大多数属于某一个类别,则该样本也属于这个类别
因为选的是k所以能避免异常值的影响

如何确定谁是我们的邻居
原理其实就是距离公式(欧氏距离)
除了欧氏距离以外还有一种叫做曼哈顿距离(绝对值距离)
明可夫斯基距离 欧氏距离和曼哈顿距离是闵可夫斯基距离的推广,是它的特殊情况

k值取得小容易受到异常值的影响
k值取的过大容易分错 受样本不均衡的影响 比如9个里面5个是远点但是反的,4个是近点但是对的 会按多的算

在knn算法之前应先对数据集进行无量纲化处理(标准化)