import pandas as pd


# 获取数据
data = pd.read_csv("./FBlocation/train.csv")


data.head()


# 进行基本数据处理
# 1 缩小数据范围
data = data.query("x<2.5 & x>2 & y<1.5 & y>1")


data.head()


# 2 处理时间特征
time_value = pd.to_datetime(data["time"],unit="s")


date = pd.DatetimeIndex(time_value)


data["day"] = date.day


data["weekday"] =  date.weekday


data["hour"] =  date.hour


data.head()


# 3 过滤掉签到次数比较少的地点
place_count = data.groupby("place_id").count()["row_id"]


place_count[place_count > 3].head() # 使用布尔索引去过滤


data_final = data[data["place_id"].isin(place_count[place_count > 3].index.values)]  # 先找到索引存在的位置 之后再对data进行布尔索引


# 筛选特征值和目标值
x = data_final[["x","y","accuracy","day","weekday","hour"]]
y = data_final["place_id"]


x.head()


y.head()


# 数据集划分
from sklearn.model_selection import train_test_split


x_train,x_test,y_train,y_test = train_test_split(x,y)


from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV


# 特征工程-标准化
transfer = StandardScaler()
x_train = transfer.fit_transform(x_train)
x_test = transfer.transform(x_test) 

estimator = KNeighborsClassifier()

param_dict = {"n_neighbors":[3,5,7,9]}
estimator = GridSearchCV(estimator, param_grid=param_dict, cv=3)


estimator.fit(x_train, y_train)

y_predict = estimator.predict(x_test)
print("预测值为：", y_predict)
print("比对真实值和预测值：", y_test == y_predict)

score = estimator.score(x_test, y_test)
print("准确率为：", score)

# 最佳参数
print("最佳参数：", estimator.best_params_)
# 最佳结果
print("最佳结果：", estimator.best_score_)
# 最佳估计器
print("最佳估计器：", estimator.best_estimator_)
# 交叉验证结果
print("交叉验证结果：", estimator.cv_results_)



