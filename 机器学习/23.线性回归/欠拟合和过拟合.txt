欠拟合是学习到的特征太少了,导致很容易预测错
训练集上表现的好 测试集表现不好就是过拟合

欠拟合在训练集和测试集都表现不好
过拟合只在测试集上表现不好

欠拟合的解决方案:
	增加特征数量

过拟合解决方案:
	正则化:让某些参数的模型系数尽可能的接近于0
	L1 L2(常用) 优化损失函数在后面增加了一个惩罚项(惩罚系数λ乘以每个权重的平方和) λ就是惩罚系数 也是可以调的超参数
	也就是说之后的运算不光要让损失函数的值变小,也要让惩罚项(权重系数)变小,从而达到不仅让模型准确还消除高次项的影响

在L2正则化（又称为Ridge正则化）中，惩罚项中的平方和是所有特征的权重平方和，而不仅仅是需要降低权重的特征

L1 正则化加的也是惩罚项 但是是绝对值增加在一起替代了平方和
如果是绝对值会使得其中一些系数的值直接为0 删除这个特征的影响 比较简单粗暴
而L2是缓和削弱

L1方法又叫LASSO
L2方法又叫Ridge - 岭回归

	